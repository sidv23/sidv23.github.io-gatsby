---
template: post
slug: stag
draft: false
socialImage: /media/stag.png
title: Statistical Learning Theory Working Group
date: 2020-08-30T22:40:32.169Z
description: Homepage for Statistical Learning Theory working group.
category: Learning Theory Group
tags:
  - Statistics
  - Learning Theory
  - stag
---
![](/media/stag.png)

The Statistical Learning Theory working group will meet on Wednesdays. We will have readings, presentations and discussions on topics including (but, not limited to) statistical learning theory, nonparametric estimation and inference, deep learning, functional data analysis, topological data analysis and algebraic statistics. The focus of the group is to read and discuss important papers in one particular topic of interest for a semester or two.

| <span style="color: red"> Time </span>         | Wednesday 2:15 - 3:45 PM                                                      |
| ---------------------------------------------- | ----------------------------------------------------------------------------- |
| <span style="color: red"> **Location** </span> | [Zoom](https://psu.zoom.us/j/8996273242?pwd=VVo5UGhydE0wZFQxRnZWcGZsbXhZUT09) |


---

## Topics

This semester we will focus on stochastic optimization. The papers we will focus on are categorized below.

1. Sampling and Gradient Flow:
    * [Francis Bach's tutorial on gradient flows](https://francisbach.com/gradient-flows/)
    * [The Variational Formulation of the Fokker-Planck Equation](https://www-dimat.unipv.it/savare/Ravello2010/JKO.pdf)
    * [Convergence of Langevin MCMC in
KL-divergence](https://arxiv.org/pdf/1705.09048.pdf)
    * [Sampling as optimization in the space of measures:
The Langevin dynamics as a composite optimization problem](https://arxiv.org/pdf/1802.08089.pdf)
    * [Sampling Can Be Faster Than Optimization](https://arxiv.org/pdf/1811.08413.pdf)
    * [Stein Variational Gradient Descent as Gradient Flow](https://arxiv.org/pdf/1704.07520.pdf)
    * [SVGD as a kernelized Wasserstein gradient flow of the chi-squared divergence](https://arxiv.org/pdf/2006.02509.pdf)
    * [Maximum Mean Discrepancy Gradient Flow](https://arxiv.org/pdf/1906.04370.pdf)
    * [A Non-Asymptotic Analysis for
Stein Variational Gradient Descent](https://arxiv.org/pdf/2006.09797.pdf)
    * [Stochastic Particle-Optimization Sampling and the Non-Asymptotic Convergence Theory](https://arxiv.org/pdf/1809.01293.pdf)
1. Langevin Monte Carlo:
    * [Theoretical guarantees for approximate sampling from smooth and log-concave densities](https://arxiv.org/pdf/1412.7392.pdf)
    * [Non-asymptotic convergence analysis for the Unadjusted Langevin Algorithm](https://arxiv.org/pdf/1507.05021.pdf)
    * [High-dimensional Bayesian inference via the Unadjusted
Langevin Algorithm](https://arxiv.org/pdf/1605.01559.pdf)
    * [Analysis of Langevin Monte Carlo via convex optimization](https://arxiv.org/pdf/1802.09188.pdf)
    * [User-friendly guarantees for the Langevin Monte Carlo with inaccurate gradient](https://arxiv.org/abs/1710.00095)
1. Optimization:
    * [A Differential Equation for Modeling Nesterovâ€™s Accelerated
Gradient Method: Theory and Insights](https://arxiv.org/pdf/1503.01243.pdf)
    * [First-order and Stochastic Optimization Methods for Machine Learning](https://link.springer.com/book/10.1007%2F978-3-030-39568-1)
    * [Non-convex Optimization for Machine Learning](https://www.prateekjain.org/publications/all_papers/JainK17_FTML.pdf)


Here is [an overview of gradient flows by Filippo Santambrogio](https://arxiv.org/pdf/1609.03890.pdf), [introductory lectures on  convex optimization by Yurii Nesterov](https://www.springer.com/gp/book/9781402075537) and the more exhaustive [lectures on  convex optimization by Yurii Nesterov](https://www.springer.com/gp/book/9783319915777).

The webpage and resources for Fall 2019 can be found [here](https://sidvishwanath.com/posts/stag-2019).

---

## Schedule

The schedule is available on the [STAG Google Calendar](https://calendar.google.com/calendar?cid=dDNqbXA3MWcyZ2Uya241NGtoN2FmbDM1dWdAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ)

<iframe src="https://calendar.google.com/calendar/embed?height=400&amp;wkst=1&amp;bgcolor=%237CB342&amp;ctz=America%2FNew_York&amp;src=dDNqbXA3MWcyZ2Uya241NGtoN2FmbDM1dWdAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ&amp;color=%238E24AA&amp;showTitle=0&amp;showNav=0&amp;showDate=1&amp;showPrint=0&amp;showTabs=1&amp;showCalendars=0&amp;mode=AGENDA" style="border-width:0" width="800" height="400" frameborder="0" scrolling="no"></iframe>


---


If you're interested in attending the meetings, please [sign-up here](https://forms.gle/xFZGmoPqh75gaj4X6), and send an email to the [L-STAT-STAG](mailto:l-stat-stag-subscribe-request@lists.psu.edu) with the subject "Add Me" and include your name and department in the body.
